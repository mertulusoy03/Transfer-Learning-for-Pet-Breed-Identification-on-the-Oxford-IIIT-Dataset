# -*- coding: utf-8 -*-
"""muhtemelUNETveyaImagenet.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1r6y1ABQ6oyKKsNlQiG2KYLoGb9FQ4hu1
"""

import numpy as np
import matplotlib.pyplot as plt
import pandas as pd
import os
import glob
import datetime

import tensorflow as tf
from tensorflow.keras.preprocessing import image
from tensorflow.keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator

!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/images.tar.gz
!wget http://www.robots.ox.ac.uk/~vgg/data/pets/data/annotations.tar.gz
!tar -xf images.tar.gz
!tar -xf annotations.tar.gz

import os

input_dir = "images/"
target_dir = "annotations/trimaps/"

input_img_paths = sorted(
    [os.path.join(input_dir, fname)
     for fname in os.listdir(input_dir)
     if fname.endswith(".jpg")])
target_paths = sorted(
    [os.path.join(target_dir, fname)
     for fname in os.listdir(target_dir)
     if fname.endswith(".png") and not fname.startswith(".")])

import matplotlib.pyplot as plt
from tensorflow.keras.utils import load_img, img_to_array
plt.imshow(load_img(input_img_paths[0]));

target = []

for breed in target_paths:
  target.append(breed.split('/',2)[2].rsplit('_',1)[0])

list_breeds  = np.unique(target)

cats_vs_dogs = [0 if i[0].isupper() == True else 1 for i in target]

labelEncDict = {name : ind for ind, name in enumerate(list_breeds)}
for k, v in labelEncDict.items():
    print(f"{k:32} : {v}")

labelDecDict = {ind: name for name, ind in labelEncDict.items()}
for k, v in labelDecDict.items():
    print(f"{k:3} : {v}")

for i in labelEncDict.keys():
    print(f"{i:32} : {target.count(i)}")

import numpy as np
import random

img_size = (224, 224)
num_imgs = len(input_img_paths)

random.Random(1337).shuffle(input_img_paths)
random.Random(1337).shuffle(target)
random.Random(1337).shuffle(cats_vs_dogs)

def path_to_input_image(path):
    img = load_img(path)
    img = tf.image.resize_with_pad(img_to_array(img, dtype = 'float32'), *img_size).numpy().astype('uint8')
    return img

input_imgs = []
targets = np.array(target)
for i in range(num_imgs):
    input_imgs.append(path_to_input_image(input_img_paths[i]))
input_imgs = np.array(input_imgs)

input_imgs.shape, targets.shape

labelsEncoded = list(map(lambda x : labelEncDict.get(x), target))

for i, l in zip(input_img_paths[::1000], labelsEncoded[::1000]):
    print(f"{i:32}\t{labelDecDict[l]:32}\t{l}")

plt.subplots(nrows = 4, ncols = 4, figsize = (20, 20))

for i, imgIndex in enumerate(np.random.randint(0, len(input_img_paths), size = 16)):
    plt.subplot(4, 4, i + 1)
    plt.axis(False)
    plt.grid(False)
    plt.title(f'{input_img_paths[imgIndex]}\n{targets[imgIndex]}\n{labelsEncoded[imgIndex]}')
    plt.imshow(input_imgs[imgIndex])
plt.show()

plt.subplots(nrows = 3, ncols = 3, figsize = (15, 12))

for i, imgIndex in enumerate(np.random.randint(0, len(input_img_paths), size = 9)):
    plt.subplot(3, 3, i + 1)
    plt.axis(False)
    plt.grid(False)
    plt.title(f'{input_img_paths[imgIndex]}\n{cats_vs_dogs[imgIndex]}')
    plt.imshow(input_imgs[imgIndex])
plt.show()

from sklearn.model_selection import train_test_split

IMAGE_SIZE = (224, 224)
RANDOM_STATE = 42
TRAIN_SIZE, VAL_SIZE, TEST_SIZE = 0.8, 0.1, 0.1

X_tv, X_test, y_tv, y_test = train_test_split(
    input_imgs,
    labelsEncoded,
    test_size = TEST_SIZE,
    random_state = RANDOM_STATE,
    stratify = targets
    )

X_train, X_val, y_train, y_val = train_test_split(
    X_tv,
    y_tv,
    test_size = VAL_SIZE,
    random_state = RANDOM_STATE,
    stratify = y_tv
    )

print(f'Training Data: {X_train.shape}')
print(f'Training Labels: {len(y_train)}')
print(f'\nValidation Data: {X_val.shape}')
print(f'Validation Labels: {len(y_val)}')
print(f'\nTesting Data: {X_test.shape}')
print(f'Testing Labels: {len(y_test)}')

train_gen = ImageDataGenerator(rescale = 1./255,
                               rotation_range = 30,
                               width_shift_range = 0.1,
                               #height_shift_range = 0.1,
                               #shear_range = 0.1,
                               #zoom_range = 0.1,
                               #horizontal_flip = True,
                               fill_mode = 'nearest',
                               #preprocessing_function=to_grayscale_then_rgb)
                               )
train_data = train_gen.flow(x = X_train, y = y_train, batch_size = 32, shuffle = True)
len(train_data)

val_gen = ImageDataGenerator(rescale = 1./255,
                             )
val_data = val_gen.flow(x = X_val, y = y_val, batch_size = 32, shuffle = True)
len(val_data)

test_gen = ImageDataGenerator(rescale = 1./255,
                             )

test_data = test_gen.flow(x = X_test, y = y_test, batch_size = 32, shuffle=False) # False because it must stay in the same order as the y_test, we will need it in the classification report
len(test_data)

del input_imgs
del labelsEncoded
del X_tv
del y_tv

def plot_generator_images(gen, suptitle, labelDecDict, print_pred = False, model = None, nrows = 3, ncols = 3, figsize = (12, 12)):
    gen_data = gen.next()

    plt.subplots(nrows = nrows, ncols = ncols, figsize = figsize)
    #plt.suptitle(suptitle, fontsize = 20)
    plt.tight_layout(rect = [0, 0, 1, 0.96], h_pad = 2)

    if(print_pred and model):
        pred = np.argmax(model.predict(gen_data[0]), axis=1)

    for i in range(nrows * ncols):
        plt.subplot(nrows, ncols, i + 1)
        plt.axis(False)
        plt.grid(False)

        if(print_pred and pred.any()):
            plt.title(f"True: {labelDecDict[gen_data[1][i]]}\nPredicted: {labelDecDict[pred[i]]}")
        else:
            plt.title(f'Label: {gen_data[1][i]}\nBreed: {labelDecDict[gen_data[1][i]]}')
        plt.imshow(gen_data[0][i])

plot_generator_images(train_data, "Training data", labelDecDict)

plot_generator_images(val_data, "Training data", labelDecDict)

from tensorflow.keras import layers
from tensorflow.keras import Sequential
from tensorflow import keras

# Using a pre-trained TF2 SavedModel from TensorFlow Hub
mobilenet_v2 ="https://tfhub.dev/google/tf2-preview/mobilenet_v2/classification/4"
resnset50 = 'https://tfhub.dev/google/imagenet/resnet_v2_50/classification/5'
efficientnetv2_s = 'https://tfhub.dev/google/imagenet/efficientnet_v2_imagenet1k_s/classification/2'

classifier_model = {'mobilenet_v2':mobilenet_v2, 'efficientnetv2_s' : efficientnetv2_s,'resnset50':resnset50}

import tensorflow_hub as hub

#%%time
histories = {}
for name in classifier_model:
    pretrained_base = hub.KerasLayer(classifier_model[name], trainable = False)
    model = keras.Sequential([
        pretrained_base,
        keras.layers.Flatten(),
        keras.layers.Dense(128,activation='relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(64,activation='relu'),
        keras.layers.Dropout(0.3),
        keras.layers.Dense(37, activation='softmax'),
    ])
    model.compile(
        optimizer='adam',
        loss = 'sparse_categorical_crossentropy',
        metrics=['accuracy'],
    )
    history = model.fit(
        train_data,
        validation_data= val_data,
        epochs=3,
    )
    histories[name] = history

for history in histories:
    plt.figure(figsize=(8, 5))
    for key, style in zip(histories[history].history, ["r--", "r--.", "b-", "b-*"]):
        epochs = np.array(histories[history].epoch) + (0 if key.startswith("val_") else -0.5)
        plt.plot(epochs, histories[history].history[key], style, label=key)
    #print(C)
    plt.title(f'{history}')
    plt.xlabel("Epoch")
    plt.axis([0.5,3, 0., 1])
    plt.legend(loc="lower right")
    plt.grid()
    plt.show()

print(C)









def plot_generator_images(gen, suptitle, labelDecDict = None, print_pred = False, model = None, nrows = 3, ncols = 3, figsize = (12, 12)):
    gen_data = gen.next()

    plt.subplots(nrows = nrows, ncols = ncols, figsize = figsize)
    #plt.suptitle(suptitle, fontsize = 20)
    plt.tight_layout(rect = [0, 0, 1, 0.96], h_pad = 2)

    if(print_pred and model):
        pred = model.predict(gen_data[0]).argmax(1)

    for i in range(nrows * ncols):
        plt.subplot(nrows, ncols, i + 1)
        plt.axis(False)
        plt.grid(False)

        if(print_pred and pred.any()):
            #plt.suptitle(suptitle, fontsize = 20)
            plt.title(f"\nTrue: {[gen_data[1][i]]}\nPredicted: {pred[i]}")
        else:
            plt.title(gen_data[1][i])
        plt.imshow(gen_data[0][i])

# Predict on the last model
plot_generator_images(test_data, "Test data vs Predicts",
                      print_pred = True,model = model)

from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dropout, Dense, LeakyReLU, BatchNormalization, Activation

base_model = keras.applications.Xception(
    weights='imagenet',
    input_shape=(224, 224, 3),
    include_top=False)

data_augmentation = Sequential(
    [
        layers.RandomFlip("horizontal"),
        layers.RandomRotation(0.1),
        layers.RandomZoom(0.2),
    ]
)

base_model.trainable=False
inputs = keras.Input(shape=(224, 224, 3))
x = base_model(inputs, training=False)
x = data_augmentation(x)
#x = Rescaling(1/255)(x)

x = keras.layers.GlobalAveragePooling2D()(x)
x = keras.layers.Dense(256)(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)

x = keras.layers.Dense(512)(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
#x = keras.layers.Dropout(0.2)(x)


x = keras.layers.Dense(512)(x)
x = BatchNormalization()(x)
x = Activation('relu')(x)
x = keras.layers.Dropout(0.3)(x)

outputs = keras.layers.Dense(37, activation='softmax')(x)
model = keras.Model(inputs, outputs)

model.summary()

from tensorflow.keras.callbacks import EarlyStopping

model.compile(loss="sparse_categorical_crossentropy",
              optimizer="rmsprop",
              metrics=["accuracy"])

es = EarlyStopping(monitor='val_loss', min_delta = 0.001, patience = 5, mode = 'auto')


callbacks = [
    keras.callbacks.ModelCheckpoint(
      filepath="base_Xception.keras",
      save_best_only=True,
      monitor="val_loss")
]

history = model.fit(train_data,epochs=100,validation_data= val_data,callbacks= [callbacks,es])

plt.figure(figsize=(8, 5))
for key, style in zip(history.history, ["r--", "r--.", "b-", "b-*"]):
    epochs = np.array(history.epoch) + (0 if key.startswith("val_") else -0.5)
    plt.plot(epochs, history.history[key], style, label=key)
plt.xlabel("Epoch")
plt.axis([-0.5, 6, 0., 1])
plt.legend(loc="lower left")
plt.grid()
plt.show()

# Evaluate the model
loss, acc = model.evaluate(test_data, verbose=2)
print("Restored model, accuracy: {:5.2f}%".format(100 * acc))

plot_generator_images(test_data, "Test data vs Predicts",
                      print_pred = True,model = model)

base_model.trainable = True
model.summary()

model.compile(
    optimizer=keras.optimizers.RMSprop(1e-5),  # Low learning rate
    loss="sparse_categorical_crossentropy",
    metrics=['accuracy']
)

epochs = 10
history = model.fit(train_data, epochs=epochs, validation_data=val_data)

plt.figure(figsize=(8, 5))
for key, style in zip(history.history, ["r--", "r--.", "b-", "b-*"]):
    epochs = np.array(history.epoch) + (0 if key.startswith("val_") else -0.5)
    plt.plot(epochs, history.history[key], style, label=key)
plt.xlabel("Epoch")
plt.axis([-0.5, 6, 0., 1])
plt.legend(loc="lower left")
plt.grid()
plt.show()

# Re-evaluate the model
loss, acc = model.evaluate(test_data, verbose=2)
print("Restored model, accuracy: {:5.2f}%".format(100 * acc))

plot_generator_images(test_data, "Test data vs Predicts",
                      print_pred = True,model = model)

preds = model.predict(test_data)

from sklearn.metrics import classification_report
print(classification_report(y_test, preds.argmax(1)))